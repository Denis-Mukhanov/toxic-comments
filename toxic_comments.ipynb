{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![image-1.png](https://i.postimg.cc/PJd3pdbG/image-1.png)](https://postimg.cc/HcP4FDP3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding:20px 20px 20px; \n",
    "            color:#004346;\n",
    "            font-size:40px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#201E20;\n",
    "            background-color: #E8F1F2;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "<p style=\"font-weight: bold; text-align: center;\"> Идентификация токсичных комментариев</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 40px 30px; \n",
    "            color:#004346;\n",
    "            font-size:110%;\n",
    "            display:fill;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#201E20;\n",
    "            background-color: #E8F1F2;\n",
    "            overflow:hidden;\n",
    "            font-weight:450;\"> \n",
    "    \n",
    "__Заказчик:__ Интернет-магазин «Викишоп».\n",
    "    \n",
    "__Постановка задачи:__ Необходимо разработать инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "    \n",
    "__Оценка результата:__ Сравнение качества работы моделей. Значение метрики качества F1 должно быть не меньше 0.75.\n",
    "    \n",
    "__Описание данных:__ Размеченные комментарии. \n",
    "    \n",
    "- `text` - текст комментария\n",
    "- `toxic` — целевой признак\n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#201E20;\n",
    "            background-color: #E8F1F2;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "# Используемые библиотеки\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/denismuhanov/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/denismuhanov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/denismuhanov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# константы\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#201E20;\n",
    "            background-color: #E8F1F2;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "# Загрузка данных\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                        text  \\\n",
       "0  Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                           D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "\n",
       "   toxic  \n",
       "0      0  \n",
       "1      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# загрузка данных:\n",
    "try:\n",
    "    df = pd.read_csv('data/toxic_comments.csv', index_col='Unnamed: 0')\n",
    "    display(df.head(2))\n",
    "except:\n",
    "    display('Данные не доступны')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:13px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#201E20;\n",
    "            background-color: #E8F1F2;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "# Предобработка и исследовательский анализ данных\n",
    "\n",
    "## Общая информация\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Проверим пропуски в данных:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общее количество пропусков в данных: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Общее количество пропусков в данных: {sum(col_pas for col_pas in df.isna().sum())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Проверим дубликатов в данных:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общее количество дубликатов в данных: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Общее количество дубликатов в данных: {df.index.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 30px 25px; border: 2px #6495ed solid\">\n",
    "\n",
    "- Данные загружены корректно.\n",
    "- Пропуски в данных отсутствуют.\n",
    "- Дублитакы в данных отсутствуют.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Баланс целевого признака__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# баланс целевого признака\n",
    "data = [df['toxic'].value_counts()[0], df['toxic'].value_counts()[1]]\n",
    "labels = ['Положительный текст', 'Отрицательный текст']\n",
    "\n",
    "colors = sns.color_palette('pastel')[ 0:5 ]\n",
    "\n",
    "plt.pie(data, labels = labels, colors = colors, autopct='%.0f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Присутствует дисдаланс классов в целевоц переменной, это надо учесть при обучении моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding:0px 20px 10px; \n",
    "            color:#004346;\n",
    "            font-size:15px;\n",
    "            display:fill;\n",
    "            text-align:center;\n",
    "            border-radius:20px;\n",
    "            border: 5px double;\n",
    "            border-color:#201E20;\n",
    "            background-color: #E8F1F2;\n",
    "            overflow:hidden;\n",
    "            font-weight:400\"> \n",
    "\n",
    "## Обработка и анализ данных\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Распределение количества символов в комментариях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# рассчет количество символов в каждом комментарии\n",
    "df['char_count'] = df['text'].apply(len)\n",
    "\n",
    "# визуализация\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(df['char_count'], bins=50, color='teal', alpha=0.7)\n",
    "plt.xlabel('Количество символов')\n",
    "plt.ylabel('Частота')\n",
    "plt.title('Распределение количества символов в комментариях')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Как видно из графика некоторые коментарии достаточно длинные, посмотрим на некотые:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57124</th>\n",
       "      <td>Fuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ...</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9664</th>\n",
       "      <td>FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIS...</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "57124  Fuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ancestryFuck-off-Jewish ...   \n",
       "9664   FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIST CUNT! FUCK YOU, YOU ATHEIS...   \n",
       "\n",
       "       toxic  char_count  \n",
       "57124      1        5000  \n",
       "9664       1        5000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# настройка \n",
    "pd.set_option(\"display.max_colwidth\", 500)\n",
    "display(df[df['char_count']==5000].sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Наблюдаем повторение одних и тех же фраз, частично данную проблему можно решить регулярными выражениями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Очистка текста__\n",
    "\n",
    "Очистим текст от небывквенных символов и части дублируемых подстрок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # перевод в нижний регист\n",
    "    text = text.lower()\n",
    "    # поиск и удаление повторяющихся подстрок\n",
    "    text = re.sub(r'(.{3,})(\\1{2,})', r'\\1', text)\n",
    "    # заменяем все символы пунктуации на пробелы\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "    text = re.sub(r\"[\\d\\n]\", \" \", text)\n",
    "    # удаление символов, которые не находятся в диапазоне ASCII \n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    # разделяем все слова и объединяем с единичным пробелом\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Частотность слов__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# токенизация текста\n",
    "df['tokens'] = df['text'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 494179, 'to': 296140, 'i': 235653, 'of': 223259, 'and': 223022, 'a': 214055, 'you': 211396, 'is': 174562, 'that': 160298, 'it': 148011, ...})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# список всех токенов\n",
    "tokens_list = [item for sublist in df['tokens'].to_list() for item in sublist]\n",
    "\n",
    "# частотность токенов\n",
    "freq_dist = FreqDist(tokens_list)\n",
    "freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>explanation</th>\n",
       "      <td>1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>why</th>\n",
       "      <td>17622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>494179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edits</th>\n",
       "      <td>9888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>made</th>\n",
       "      <td>9648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webaddress</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gratest</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hanumakonda</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>automakers</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ciu</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172420 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               freq\n",
       "explanation    1768\n",
       "why           17622\n",
       "the          494179\n",
       "edits          9888\n",
       "made           9648\n",
       "...             ...\n",
       "webaddress        1\n",
       "gratest           1\n",
       "hanumakonda       1\n",
       "automakers        1\n",
       "ciu               1\n",
       "\n",
       "[172420 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# перевод частотности в датафрейм\n",
    "freq_df = pd.DataFrame.from_dict(freq_dist, orient='index', columns=['freq'])\n",
    "display(freq_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Посмотрим наиболее редкие значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>good_article_nominations</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shirvington</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dulithgow</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wonju</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talibans</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webaddress</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gratest</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hanumakonda</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>automakers</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ciu</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146296 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          freq\n",
       "good_article_nominations     1\n",
       "shirvington                  1\n",
       "dulithgow                    3\n",
       "wonju                        4\n",
       "talibans                     7\n",
       "...                        ...\n",
       "webaddress                   1\n",
       "gratest                      1\n",
       "hanumakonda                  1\n",
       "automakers                   1\n",
       "ciu                          1\n",
       "\n",
       "[146296 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_df[freq_df['freq'] < 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Можно увидеть, что в тексте присутствует так же нижнии подчеркивания, посмотрим текст где используются данные символы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can t make any real suggestions on improvement i wondered if the section statistics should be later on or a subsection of types of accidents i think the references may need tidying so that they are all in the exact same format ie date format etc i can do that later on if no one else does first if you have any preferences for formatting style on references or want to do it yourself please let me know there appears to be a backlog on articles for review so i guess there may be a delay u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>i was able to post the above list so quickly because i already had it in a text file in my hard drive i ve been meaning to get around to updating the sound list for some time now as far as generating interest i ve spent four years trying to drum up more interest in freely licensed full length classical music unfortunately my attempts failed i m still effectively the only one who does it the classical music wikiproject was not interested wikipedia_talk wikiproject_classical_music archive_ nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>well not before the process but before how we do things with subpages his rfa is listed on noseptember s page and you can find it if you look september i think i have my differences with el_c to be sure but was surprised to see a block so i left a note t c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>transliteration of russian place names in writing about moscow metro for the malayalam wikipedia we are finding it difficult to correctly transliterate the russian place names for example do we pronounce park kultury as paark kalttari or paark kalchchari or perhaps something completely different can somebody please help by transliterating the list given in https ml wikipedia org wiki _ i am not putting the list here as i don t want to clutter up this page thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>thanks i can see that violating clearly stated wikipedia policy is no problem with some people as is now being reviewed elsewhere finishing up one other wiki project todsy and then spending the rest of the day on an important personal blog entry then i ll go find other discussions of james petras fascinating discussion of the use of the term jewish lobby so that i don t have to put back up the deleted dissident voice article right away per talk jewish_lobby wp v_ _comparing_jewish_virtual_li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159197</th>\n",
       "      <td>atomic er user atomic er since i own all copyrights to the gas theory and gravitation and any and all works by me and you previously rejected these works i now prohibit you from posting any mention of these works other than that which i myself have posted you rejected my copyright yet i own those pages in question i am not and was not offended however i deny wikipedia as a credible source i have encouraged google to produce encylopediactionary all the worlds encyclopedias and dictionaries in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159224</th>\n",
       "      <td>jprw please visit this link to better understand how wikipedia works http en wikipedia org wiki wikipedia biographies_of_living_persons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159255</th>\n",
       "      <td>hello i keep getting a message from another user stating that i am vandalizing a page which clearly am not please go to http en wikipedia org wiki talk nissan_gt r under overwhelmingly published articles state the nissan gtr is a supercar what have i done wrong and why are they not following the rules set forth by wikipeadia please help thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159297</th>\n",
       "      <td>news suppressed on wikipedia http rexcurry net wikipedialies html rexcurry net is the historian who made the following discoveries covered elsewhere and on wikipedia the usa s first pledge used a straight arm salute and it was the origin of the salute of the monstrous national socialist german workers party nazis it was not an ancient roman salute http rexcurry net pledgesalute html the pledge began with a military salute that then stretched outward toward the flag historic photographs are a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159388</th>\n",
       "      <td>apparently palit is found to be worthy of mention by nvidia amazon and pcuniverse http www nvidia com object io_ _ html http www amazon com tag palit microsystems http www pcuniverse com palit microsystems bs h anyone familiar with newegg knows that it is a top internet retailer in terms of sales putting it ahead of bestbuy com etc i believe it is the electronics internet retailer behind dell com if your products are on newegg and on the front page of their video card section you deserve at ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4363 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       text\n",
       "3       more i can t make any real suggestions on improvement i wondered if the section statistics should be later on or a subsection of types of accidents i think the references may need tidying so that they are all in the exact same format ie date format etc i can do that later on if no one else does first if you have any preferences for formatting style on references or want to do it yourself please let me know there appears to be a backlog on articles for review so i guess there may be a delay u...\n",
       "33      i was able to post the above list so quickly because i already had it in a text file in my hard drive i ve been meaning to get around to updating the sound list for some time now as far as generating interest i ve spent four years trying to drum up more interest in freely licensed full length classical music unfortunately my attempts failed i m still effectively the only one who does it the classical music wikiproject was not interested wikipedia_talk wikiproject_classical_music archive_ nee...\n",
       "34                                                                                                                                                                                                                                                         well not before the process but before how we do things with subpages his rfa is listed on noseptember s page and you can find it if you look september i think i have my differences with el_c to be sure but was surprised to see a block so i left a note t c\n",
       "91                                       transliteration of russian place names in writing about moscow metro for the malayalam wikipedia we are finding it difficult to correctly transliterate the russian place names for example do we pronounce park kultury as paark kalttari or paark kalchchari or perhaps something completely different can somebody please help by transliterating the list given in https ml wikipedia org wiki _ i am not putting the list here as i don t want to clutter up this page thanks\n",
       "95      thanks i can see that violating clearly stated wikipedia policy is no problem with some people as is now being reviewed elsewhere finishing up one other wiki project todsy and then spending the rest of the day on an important personal blog entry then i ll go find other discussions of james petras fascinating discussion of the use of the term jewish lobby so that i don t have to put back up the deleted dissident voice article right away per talk jewish_lobby wp v_ _comparing_jewish_virtual_li...\n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ...\n",
       "159197  atomic er user atomic er since i own all copyrights to the gas theory and gravitation and any and all works by me and you previously rejected these works i now prohibit you from posting any mention of these works other than that which i myself have posted you rejected my copyright yet i own those pages in question i am not and was not offended however i deny wikipedia as a credible source i have encouraged google to produce encylopediactionary all the worlds encyclopedias and dictionaries in...\n",
       "159224                                                                                                                                                                                                                                                                                                                                                                              jprw please visit this link to better understand how wikipedia works http en wikipedia org wiki wikipedia biographies_of_living_persons\n",
       "159255                                                                                                                                                         hello i keep getting a message from another user stating that i am vandalizing a page which clearly am not please go to http en wikipedia org wiki talk nissan_gt r under overwhelmingly published articles state the nissan gtr is a supercar what have i done wrong and why are they not following the rules set forth by wikipeadia please help thank you\n",
       "159297  news suppressed on wikipedia http rexcurry net wikipedialies html rexcurry net is the historian who made the following discoveries covered elsewhere and on wikipedia the usa s first pledge used a straight arm salute and it was the origin of the salute of the monstrous national socialist german workers party nazis it was not an ancient roman salute http rexcurry net pledgesalute html the pledge began with a military salute that then stretched outward toward the flag historic photographs are a...\n",
       "159388  apparently palit is found to be worthy of mention by nvidia amazon and pcuniverse http www nvidia com object io_ _ html http www amazon com tag palit microsystems http www pcuniverse com palit microsystems bs h anyone familiar with newegg knows that it is a top internet retailer in terms of sales putting it ahead of bestbuy com etc i believe it is the electronics internet retailer behind dell com if your products are on newegg and on the front page of their video card section you deserve at ...\n",
       "\n",
       "[4363 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 500)\n",
    "df[df.text.str.contains('_')][['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__stopwords/word_tokenize__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(10000).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    10000 non-null  object\n",
      " 1   toxic   10000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализация токенизатора\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Проверим длинну текстов__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальная длинна текста составляет: 5000 символов\n"
     ]
    }
   ],
   "source": [
    "print(f'Максимальная длинна текста составляет: {max(map(len, df_sample[\"text\"]))} символов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Минимальная длинна текста составляет: 16 символов\n"
     ]
    }
   ],
   "source": [
    "print(f'Минимальная длинна текста составляет: {min(map(len, df_sample[\"text\"]))} символов')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Стандартная версия модели BERT ('bert-base-cased') имеет ограничение на максимальную длину последовательности, и это ограничение составляет 512 токенов. Это связано с ограниченной памятью графических процессоров (GPU) и вычислительной сложностью обработки более длинных последовательностей при обучении модели.\n",
    "- Мы можем разделить длинные тексты на более короткие части, учитывая минимальную длинну изначальных текстов, тем самым увеличим датафрейм и стандартизируем данные для правильной работы молели BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка длинных текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510 16\n"
     ]
    }
   ],
   "source": [
    "# максимальная длина последовательности\n",
    "max_seq_length = 510\n",
    "# минимальная длина последовательности (5)\n",
    "min_seq_length = min(map(len, df_sample[\"text\"]))\n",
    "print(max_seq_length, min_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Список стандартизированных строк готов\n"
     ]
    }
   ],
   "source": [
    "# список для новых строк\n",
    "new_rows = []\n",
    "# функция для разделения\n",
    "def split(x):\n",
    "    # разделение на части\n",
    "    chunks = [' '.join((x['text'][i:i + max_seq_length]).split()[:-1]) for i in range(0, len(x['text']), max_seq_length)]\n",
    "    # cоздание новых строк для каждой части\n",
    "    for chunk in chunks:\n",
    "        if len(chunk) >= min_seq_length:\n",
    "            new_row = {'text': chunk, 'toxic': x['toxic']}\n",
    "            new_rows.append(new_row)\n",
    "            \n",
    "df_sample.apply(split, axis=1)\n",
    "print('Список стандартизированных строк готов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13936 entries, 0 to 13935\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    13936 non-null  object\n",
      " 1   toxic   13936 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 217.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" The image was marked for deletion as a copyr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\" IP block extensions While I completely agree...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  \" The image was marked for deletion as a copyr...      0\n",
       "1  \" IP block extensions While I completely agree...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет увеличился на 39%\n"
     ]
    }
   ],
   "source": [
    "# создание обновленного датасета и вывод основной информации\n",
    "df_split_sample = pd.DataFrame(new_rows)\n",
    "print(df_split_sample.info())\n",
    "display(df_split_sample.head(2))\n",
    "print(f'Датасет увеличился на {(len(df_split_sample)-len(df_sample))/len(df_sample):.0%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 224778 entries, 0 to 224777\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    224778 non-null  object\n",
      " 1   toxic   224778 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.4+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет увеличился на 41%\n"
     ]
    }
   ],
   "source": [
    "# создание обновленного датасета и вывод основной информации\n",
    "df_split = pd.DataFrame(new_rows)\n",
    "print(df_split.info())\n",
    "display(df_split.head(2))\n",
    "print(f'Датасет увеличился на {(len(df_split)-len(df))/len(df):.0%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# токенизация данных\n",
    "tokenized = df_split_sample['text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13936"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Паддинг данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Максимальная длина среди токенов составляет: 425\n"
     ]
    }
   ],
   "source": [
    "# максимальная длина среди токенов\n",
    "max_len = max(map(len, tokenized))\n",
    "print(f' Максимальная длина среди токенов составляет: {max_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# паддинг данных\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized])\n",
    "\n",
    "# создание маски внимания\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13936"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(map(len, padded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эмбеддинги текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# загрузка конфигурации\n",
    "config = transformers.BertConfig.from_pretrained('bert-base-cased')\n",
    "\n",
    "# загрузка модели\n",
    "model = transformers.BertModel.from_pretrained('bert-base-cased', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c90d42358b943aab5236200cb33f361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m attention_mask_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(attention_mask[batch_size\u001b[38;5;241m*\u001b[39mi:batch_size\u001b[38;5;241m*\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 16\u001b[0m     batch_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m embeddings\u001b[38;5;241m.\u001b[39mappend(batch_embeddings[\u001b[38;5;241m0\u001b[39m][:,\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1020\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1011\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1013\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1014\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1015\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1019\u001b[0m )\n\u001b[0;32m-> 1020\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1032\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1033\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:610\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    601\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    602\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    603\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    607\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    608\u001b[0m     )\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 610\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:495\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    485\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    492\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    494\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:425\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    417\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    424\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 425\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    435\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:353\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    350\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m attention_mask\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# Normalize the attention scores to probabilities.\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_probs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/functional.py:1813\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1809\u001b[0m         ret \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;28minput\u001b[39m)\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[0;32m-> 1813\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msoftmax\u001b[39m(\u001b[38;5;28minput\u001b[39m: Tensor, dim: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, _stacklevel: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, dtype: Optional[DType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m   1814\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies a softmax function.\u001b[39;00m\n\u001b[1;32m   1815\u001b[0m \n\u001b[1;32m   1816\u001b[0m \u001b[38;5;124;03m    Softmax is defined as:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1836\u001b[0m \n\u001b[1;32m   1837\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1838\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "batch_size = 536\n",
    "embeddings = []\n",
    "\n",
    "# Переносим модель на Metal Performance Shaders (MPS)\n",
    "device = torch.device(\"mps\")\n",
    "model.to(device)\n",
    "\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print (torch.backends.mps.is_available()) #macOS выше 12.3+ \n",
    "print (torch.backends.mps.is_built()) #MPS активирован"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_split_sample['toxic'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1370"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Создание тренировочного и тестового наборов с сохранением баланса классов\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.6/235.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /Users/denismuhanov/miniconda3/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/denismuhanov/miniconda3/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/denismuhanov/miniconda3/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/denismuhanov/miniconda3/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/denismuhanov/miniconda3/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.23.5)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.11.0 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "! pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 101, 1: 101})\n"
     ]
    }
   ],
   "source": [
    "# Подсчет количества классов в y_train\n",
    "class_counts = Counter(y_train)\n",
    "\n",
    "# Определение количества примеров для undersampling\n",
    "minority_class_count = class_counts[1]  # Меньший класс\n",
    "majority_class_count = class_counts[0]  # Больший класс\n",
    "desired_majority_class_count = minority_class_count  # Задайте желаемое количество примеров для класса 0\n",
    "\n",
    "# Создание объекта RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy={0: desired_majority_class_count, 1: minority_class_count})\n",
    "\n",
    "# Применение undersampling к данным\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Проверка новых балансов классов\n",
    "print(Counter(y_train_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = LogisticRegression(max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/denismuhanov/miniconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mod.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8250728862973761\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47368421052631576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    358\n",
       "1     42\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.6-py3-none-macosx_12_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /Users/denismuhanov/miniconda3/lib/python3.10/site-packages (from xgboost) (1.10.1)\n",
      "Requirement already satisfied: numpy in /Users/denismuhanov/miniconda3/lib/python3.10/site-packages (from xgboost) (1.23.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.6\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Создание объекта DMatrix\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "# Обучение модели\n",
    "num_round = 100\n",
    "model = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "# Предсказания\n",
    "y_pred = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Оценка модели по F1\n",
    "f1 = f1_score(y_test, (y_pred > 0.5).astype(int))\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 112,
    "start_time": "2023-08-23T14:26:38.893Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
